{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 1 - PDM - Vicente Espinoza - Marcelo Vargas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import kshingle as ks\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer as TbWD\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_parecidos(username, k, dframe, lsh):\n",
    "    # Input: Username (str)\n",
    "\n",
    "    # Output: Lista de Username de usuarios que han escrito tweets similares\n",
    "\n",
    "    listindex = list(dframe[dframe['screen_name'] == username].index)\n",
    "\n",
    "    users_similares= dict()\n",
    "\n",
    "    for indexuser in listindex:\n",
    "        minhash = dframe.loc[indexuser]['shingles']\n",
    "        for user_id in lsh.query(minhash):\n",
    "            similar_name = dframe.loc[user_id]['screen_name']\n",
    "            \n",
    "            if similar_name != username:\n",
    "                users_similares[similar_name] = users_similares.get(similar_name, 0) + 1\n",
    "\n",
    "    finallist = [(name,value) for name,value in users_similares.items()]\n",
    "\n",
    "    finallist.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return finallist[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_emojis(texto):\n",
    "    # Expresión regular para eliminar emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticones\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # símbolos y pictogramas\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transporte y símbolos de mapa\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # banderas de países\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # caracteres chinos, japoneses y coreanos (CJK)\n",
    "                               u\"\\U00002702-\\U000027B0\"  # símbolos de negocio\n",
    "                               u\"\\U00002702-\\U000027B0\"  # flechas y símbolos diversos\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    # Eliminar emojis\n",
    "    texto_sin_emojis = emoji_pattern.sub(r'', texto)\n",
    "    \n",
    "    # Preservar letras con tildes, la letra \"ñ\" y símbolos específicos\n",
    "    texto_limpio = re.sub(r'[^a-zA-Zá-úÁ-ÚñÑ@/: ,.;-_]+', '', texto_sin_emojis)\n",
    "    \n",
    "    return texto_limpio\n",
    "\n",
    "def set_to_minhash(set, minhash):\n",
    "    for shingle in set:\n",
    "        minhash.update(shingle.encode('utf-8'))\n",
    "\n",
    "    return minhash\n",
    "\n",
    "def buscar_parecidos(username, k, dframe, lsh):\n",
    "    # Input: Username (str)\n",
    "\n",
    "    # Output: Lista de Username de usuarios que han escrito tweets similares\n",
    "\n",
    "    listindex = list(dframe[dframe['screen_name'] == username].index)\n",
    "\n",
    "    users_similares= dict()\n",
    "\n",
    "    for indexuser in listindex:\n",
    "        minhash = dframe.loc[indexuser]['shingles']\n",
    "        for user_id in lsh.query(minhash):\n",
    "            similar_name = dframe.loc[user_id]['screen_name']\n",
    "            \n",
    "            if similar_name != username:\n",
    "                users_similares[similar_name] = users_similares.get(similar_name, 0) + 1\n",
    "\n",
    "    finallist = [(name,value) for name,value in users_similares.items()]\n",
    "\n",
    "    finallist.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return finallist[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_spanish = (stopwords.words('spanish'))\n",
    "\n",
    "df = pd.read_csv('tweets_2022_abril_junio.csv', usecols = ['id', 'screen_name', 'text'], index_col = \"id\")\n",
    "df = df[~df.index.duplicated(keep='first')]\n",
    "df = df[df[\"text\"].str[:2] != \"RT\"]\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: TbWD().detokenize([word for word in eliminar_emojis(x.lower()).split(' ') if word not in stopwords_spanish]))\n",
    "df['shingles'] = df[\"text\"].apply(lambda x: ks.shingleset_list(x, [3]))\n",
    "\n",
    "df[\"shingles\"] = df[\"shingles\"].apply(lambda x: set_to_minhash(x, MinHash(128)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh = MinHashLSH(threshold = 0.5, num_perm = 128)\n",
    "for ind in df.index:\n",
    "    lsh.insert(ind, df[\"shingles\"][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pita09443405', 441),\n",
       " ('Arnold73020321', 289),\n",
       " ('Sergio_Valech', 172),\n",
       " ('JCCONTACTOSUR', 150),\n",
       " ('LuzTamu', 142),\n",
       " ('karinwinder', 139)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buscar_parecidos('MacaSimplemente', 6, df, lsh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
